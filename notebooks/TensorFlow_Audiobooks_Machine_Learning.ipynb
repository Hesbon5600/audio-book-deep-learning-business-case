{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data\n",
    "\n",
    "That's where we load and preprocess our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processe_data_path = os.path.join(os.path.pardir, 'data', 'processed')\n",
    "\n",
    "# let's create a temporary variable npz, where we will store each of the three Audiobooks datasets\n",
    "\n",
    "npz_train = np.load(os.path.join(pre_processe_data_path, 'Audiobooks_data_train.npz'))\n",
    "\n",
    "# we extract the inputs using the keyword under which we saved them\n",
    "# to ensure that they are all floats, let's also take care of that\n",
    "\n",
    "train_inputs = npz_train['inputs'].astype(np.float)\n",
    "# targets must be int because of sparse_categorical_crossentropy (we want to be able to smoothly one-hot encode them)\n",
    "train_targets = npz_train['targets'].astype(np.int)\n",
    "\n",
    "# we load the validation data in the temporary variable\n",
    "npz_validation = np.load(os.path.join(pre_processe_data_path, 'Audiobooks_data_validation.npz'))\n",
    "\n",
    "# we can load the inputs and the targets in the same line\n",
    "validation_inputs = npz_validation['inputs'].astype(np.float)\n",
    "validation_targets = npz_validation['targets'].astype(np.int)\n",
    "\n",
    "# we load the test data in the temporary variable\n",
    "npz_test = np.load(os.path.join(pre_processe_data_path, 'Audiobooks_data_test.npz'))\n",
    "\n",
    "# we create 2 variables that will contain the test inputs and the test targets\n",
    "test_inputs = npz_test['inputs'].astype(np.float)\n",
    "test_targets = npz_test['targets'].astype(np.int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Outline, optimizers, loss, early stopping and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3579 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "3579/3579 - 0s - loss: 0.5689 - accuracy: 0.7882 - val_loss: 0.4370 - val_accuracy: 0.8591\n",
      "Epoch 2/100\n",
      "3579/3579 - 0s - loss: 0.3742 - accuracy: 0.8748 - val_loss: 0.3413 - val_accuracy: 0.8770\n",
      "Epoch 3/100\n",
      "3579/3579 - 0s - loss: 0.3220 - accuracy: 0.8829 - val_loss: 0.3166 - val_accuracy: 0.8792\n",
      "Epoch 4/100\n",
      "3579/3579 - 0s - loss: 0.2974 - accuracy: 0.8908 - val_loss: 0.3005 - val_accuracy: 0.8792\n",
      "Epoch 5/100\n",
      "3579/3579 - 0s - loss: 0.2820 - accuracy: 0.8969 - val_loss: 0.2900 - val_accuracy: 0.8837\n",
      "Epoch 6/100\n",
      "3579/3579 - 0s - loss: 0.2712 - accuracy: 0.8989 - val_loss: 0.2828 - val_accuracy: 0.8859\n",
      "Epoch 7/100\n",
      "3579/3579 - 0s - loss: 0.2664 - accuracy: 0.9000 - val_loss: 0.2795 - val_accuracy: 0.8881\n",
      "Epoch 8/100\n",
      "3579/3579 - 0s - loss: 0.2592 - accuracy: 0.9014 - val_loss: 0.2757 - val_accuracy: 0.8926\n",
      "Epoch 9/100\n",
      "3579/3579 - 0s - loss: 0.2549 - accuracy: 0.9033 - val_loss: 0.2723 - val_accuracy: 0.8949\n",
      "Epoch 10/100\n",
      "3579/3579 - 0s - loss: 0.2517 - accuracy: 0.9042 - val_loss: 0.2691 - val_accuracy: 0.8949\n",
      "Epoch 11/100\n",
      "3579/3579 - 0s - loss: 0.2498 - accuracy: 0.9028 - val_loss: 0.2697 - val_accuracy: 0.8949\n",
      "Epoch 12/100\n",
      "3579/3579 - 0s - loss: 0.2459 - accuracy: 0.9064 - val_loss: 0.2649 - val_accuracy: 0.8971\n",
      "Epoch 13/100\n",
      "3579/3579 - 0s - loss: 0.2443 - accuracy: 0.9075 - val_loss: 0.2664 - val_accuracy: 0.8949\n",
      "Epoch 14/100\n",
      "3579/3579 - 0s - loss: 0.2408 - accuracy: 0.9084 - val_loss: 0.2613 - val_accuracy: 0.8971\n",
      "Epoch 15/100\n",
      "3579/3579 - 0s - loss: 0.2391 - accuracy: 0.9061 - val_loss: 0.2631 - val_accuracy: 0.8993\n",
      "Epoch 16/100\n",
      "3579/3579 - 0s - loss: 0.2383 - accuracy: 0.9109 - val_loss: 0.2674 - val_accuracy: 0.9016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12e074ac8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the input and output sizes\n",
    "input_size = 10\n",
    "output_size = 2\n",
    "# Use same hidden layer size for both hidden layers. Not a necessity.\n",
    "hidden_layer_size = 50\n",
    "    \n",
    "# define how the model will look like\n",
    "model = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n",
    "    # it takes several arguments, but the most important ones for us are the hidden_layer_size and the activation function\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
    "    # the final layer is no different, we just make sure to activate it with softmax\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
    "])\n",
    "\n",
    "\n",
    "### Choose the optimizer and the loss function\n",
    "\n",
    "# we define the optimizer we'd like to use, \n",
    "# the loss function, \n",
    "# and the metrics we are interested in obtaining at each iteration\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "### Training\n",
    "# That's where we train the model we have built.\n",
    "\n",
    "# set the batch size\n",
    "batch_size = 100\n",
    "\n",
    "# set a maximum number of training epochs\n",
    "max_epochs = 100\n",
    "\n",
    "# set an early stopping mechanism\n",
    "# let's set patience=2, to be a bit tolerant against random validation loss increases\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "# fit the model\n",
    "# note that this time the train, validation and test data are not iterable\n",
    "model.fit(train_inputs, # train inputs\n",
    "          train_targets, # train targets\n",
    "          batch_size=batch_size, # batch size\n",
    "          epochs=max_epochs, # epochs that we will train for (assuming early stopping doesn't kick in)\n",
    "          # callbacks are functions called by a task when a task is completed\n",
    "          # task here is to check if val_loss is increasing\n",
    "          callbacks=[early_stopping], # early stopping\n",
    "          validation_data=(validation_inputs, validation_targets), # validation data\n",
    "          verbose = 2 # making sure we get enough information about the training process\n",
    "          )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "As we discussed in the lectures, after training on the training data and validating on the validation data, we test the final prediction power of our model by running it on the test dataset that the algorithm has NEVER seen before.\n",
    "\n",
    "It is very important to realize that fiddling with the hyperparameters overfits the validation dataset. \n",
    "\n",
    "The test is the absolute final instance. You should not test before you are completely done with adjusting your model.\n",
    "\n",
    "If you adjust your model after testing, you will start overfitting the test dataset, which will defeat its purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 0s 66us/sample - loss: 0.2611 - accuracy: 0.9107\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.26. Test accuracy: 91.07%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the initial model and hyperparameters given in this notebook, the final test accuracy should be roughly around 91%.\n",
    "\n",
    "Note that each time the code is rerun, we get a different accuracy because each training is different. \n",
    "\n",
    "We have intentionally reached a suboptimal solution, so you can have space to build on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0 prediction: Not-Buy (69.2%)\n",
      "Example 1 prediction: Buy (70.9%)\n",
      "Example 2 prediction: Not-Buy (72.8%)\n",
      "Example 3 prediction: Not-Buy (55.7%)\n",
      "Example 4 prediction: Buy (70.5%)\n",
      "Example 5 prediction: Not-Buy (68.2%)\n",
      "Example 6 prediction: Not-Buy (73.1%)\n",
      "Example 7 prediction: Not-Buy (65.7%)\n",
      "Example 8 prediction: Not-Buy (56.4%)\n",
      "Example 9 prediction: Not-Buy (61.2%)\n",
      "Example 10 prediction: Not-Buy (65.8%)\n",
      "Example 11 prediction: Buy (70.5%)\n",
      "Example 12 prediction: Not-Buy (65.8%)\n",
      "Example 13 prediction: Not-Buy (73.1%)\n",
      "Example 14 prediction: Buy (69.3%)\n",
      "Example 15 prediction: Not-Buy (67.6%)\n",
      "Example 16 prediction: Not-Buy (65.3%)\n",
      "Example 17 prediction: Buy (72.1%)\n",
      "Example 18 prediction: Buy (73.1%)\n",
      "Example 19 prediction: Buy (70.9%)\n",
      "Example 20 prediction: Buy (71.3%)\n",
      "Example 21 prediction: Not-Buy (62.5%)\n",
      "Example 22 prediction: Not-Buy (73.1%)\n",
      "Example 23 prediction: Not-Buy (73.0%)\n",
      "Example 24 prediction: Buy (68.4%)\n",
      "Example 25 prediction: Buy (71.7%)\n",
      "Example 26 prediction: Not-Buy (61.9%)\n",
      "Example 27 prediction: Buy (72.7%)\n",
      "Example 28 prediction: Buy (70.5%)\n",
      "Example 29 prediction: Buy (59.2%)\n",
      "Example 30 prediction: Not-Buy (73.0%)\n",
      "Example 31 prediction: Buy (69.1%)\n",
      "Example 32 prediction: Buy (70.8%)\n",
      "Example 33 prediction: Not-Buy (68.2%)\n",
      "Example 34 prediction: Buy (72.9%)\n",
      "Example 35 prediction: Buy (73.0%)\n",
      "Example 36 prediction: Buy (68.5%)\n",
      "Example 37 prediction: Not-Buy (58.2%)\n",
      "Example 38 prediction: Buy (70.0%)\n",
      "Example 39 prediction: Buy (72.4%)\n",
      "Example 40 prediction: Buy (72.5%)\n",
      "Example 41 prediction: Buy (71.1%)\n",
      "Example 42 prediction: Buy (70.9%)\n",
      "Example 43 prediction: Not-Buy (67.1%)\n",
      "Example 44 prediction: Buy (68.0%)\n",
      "Example 45 prediction: Not-Buy (66.1%)\n",
      "Example 46 prediction: Not-Buy (73.1%)\n",
      "Example 47 prediction: Buy (68.1%)\n",
      "Example 48 prediction: Buy (70.4%)\n",
      "Example 49 prediction: Not-Buy (63.6%)\n",
      "Example 50 prediction: Not-Buy (73.1%)\n",
      "Example 51 prediction: Buy (66.2%)\n",
      "Example 52 prediction: Not-Buy (73.1%)\n",
      "Example 53 prediction: Buy (70.9%)\n",
      "Example 54 prediction: Not-Buy (73.1%)\n",
      "Example 55 prediction: Not-Buy (71.7%)\n",
      "Example 56 prediction: Not-Buy (73.1%)\n",
      "Example 57 prediction: Buy (70.3%)\n",
      "Example 58 prediction: Buy (73.1%)\n",
      "Example 59 prediction: Buy (73.1%)\n",
      "Example 60 prediction: Buy (73.1%)\n",
      "Example 61 prediction: Buy (73.0%)\n",
      "Example 62 prediction: Buy (71.7%)\n",
      "Example 63 prediction: Not-Buy (73.0%)\n",
      "Example 64 prediction: Buy (71.2%)\n",
      "Example 65 prediction: Not-Buy (65.9%)\n",
      "Example 66 prediction: Buy (69.9%)\n",
      "Example 67 prediction: Not-Buy (73.1%)\n",
      "Example 68 prediction: Not-Buy (66.7%)\n",
      "Example 69 prediction: Buy (71.0%)\n",
      "Example 70 prediction: Not-Buy (73.1%)\n",
      "Example 71 prediction: Not-Buy (65.3%)\n",
      "Example 72 prediction: Buy (73.1%)\n",
      "Example 73 prediction: Buy (73.1%)\n",
      "Example 74 prediction: Not-Buy (53.9%)\n",
      "Example 75 prediction: Buy (71.8%)\n",
      "Example 76 prediction: Buy (54.6%)\n",
      "Example 77 prediction: Not-Buy (66.9%)\n",
      "Example 78 prediction: Buy (71.1%)\n",
      "Example 79 prediction: Buy (73.1%)\n",
      "Example 80 prediction: Buy (62.5%)\n",
      "Example 81 prediction: Buy (68.2%)\n",
      "Example 82 prediction: Buy (70.4%)\n",
      "Example 83 prediction: Buy (73.1%)\n",
      "Example 84 prediction: Buy (73.1%)\n",
      "Example 85 prediction: Not-Buy (73.1%)\n",
      "Example 86 prediction: Not-Buy (52.6%)\n",
      "Example 87 prediction: Not-Buy (73.1%)\n",
      "Example 88 prediction: Not-Buy (54.6%)\n",
      "Example 89 prediction: Buy (70.4%)\n",
      "Example 90 prediction: Not-Buy (73.1%)\n",
      "Example 91 prediction: Buy (73.1%)\n",
      "Example 92 prediction: Buy (71.2%)\n",
      "Example 93 prediction: Not-Buy (65.4%)\n",
      "Example 94 prediction: Buy (57.4%)\n",
      "Example 95 prediction: Buy (67.5%)\n",
      "Example 96 prediction: Buy (71.8%)\n",
      "Example 97 prediction: Buy (71.7%)\n",
      "Example 98 prediction: Not-Buy (73.1%)\n",
      "Example 99 prediction: Not-Buy (67.4%)\n",
      "Example 100 prediction: Buy (66.0%)\n",
      "Example 101 prediction: Buy (73.1%)\n",
      "Example 102 prediction: Buy (70.9%)\n",
      "Example 103 prediction: Buy (73.1%)\n",
      "Example 104 prediction: Buy (70.5%)\n",
      "Example 105 prediction: Not-Buy (62.2%)\n",
      "Example 106 prediction: Buy (72.7%)\n",
      "Example 107 prediction: Buy (71.2%)\n",
      "Example 108 prediction: Not-Buy (60.5%)\n",
      "Example 109 prediction: Not-Buy (68.8%)\n",
      "Example 110 prediction: Not-Buy (65.8%)\n",
      "Example 111 prediction: Buy (55.8%)\n",
      "Example 112 prediction: Buy (71.2%)\n",
      "Example 113 prediction: Buy (73.1%)\n",
      "Example 114 prediction: Not-Buy (73.1%)\n",
      "Example 115 prediction: Not-Buy (73.1%)\n",
      "Example 116 prediction: Buy (73.1%)\n",
      "Example 117 prediction: Buy (70.6%)\n",
      "Example 118 prediction: Not-Buy (70.6%)\n",
      "Example 119 prediction: Buy (69.2%)\n",
      "Example 120 prediction: Buy (67.0%)\n",
      "Example 121 prediction: Not-Buy (61.7%)\n",
      "Example 122 prediction: Not-Buy (72.7%)\n",
      "Example 123 prediction: Not-Buy (72.0%)\n",
      "Example 124 prediction: Buy (73.1%)\n",
      "Example 125 prediction: Buy (70.2%)\n",
      "Example 126 prediction: Not-Buy (67.4%)\n",
      "Example 127 prediction: Buy (73.1%)\n",
      "Example 128 prediction: Not-Buy (65.8%)\n",
      "Example 129 prediction: Not-Buy (72.8%)\n",
      "Example 130 prediction: Buy (63.6%)\n",
      "Example 131 prediction: Buy (73.1%)\n",
      "Example 132 prediction: Buy (73.0%)\n",
      "Example 133 prediction: Buy (71.4%)\n",
      "Example 134 prediction: Not-Buy (50.7%)\n",
      "Example 135 prediction: Not-Buy (59.9%)\n",
      "Example 136 prediction: Not-Buy (73.1%)\n",
      "Example 137 prediction: Buy (73.1%)\n",
      "Example 138 prediction: Buy (71.9%)\n",
      "Example 139 prediction: Not-Buy (65.4%)\n",
      "Example 140 prediction: Buy (66.6%)\n",
      "Example 141 prediction: Not-Buy (73.1%)\n",
      "Example 142 prediction: Buy (70.4%)\n",
      "Example 143 prediction: Not-Buy (68.6%)\n",
      "Example 144 prediction: Not-Buy (59.9%)\n",
      "Example 145 prediction: Buy (73.1%)\n",
      "Example 146 prediction: Buy (68.9%)\n",
      "Example 147 prediction: Not-Buy (68.3%)\n",
      "Example 148 prediction: Buy (73.1%)\n",
      "Example 149 prediction: Not-Buy (65.5%)\n",
      "Example 150 prediction: Buy (73.1%)\n",
      "Example 151 prediction: Not-Buy (67.1%)\n",
      "Example 152 prediction: Not-Buy (59.9%)\n",
      "Example 153 prediction: Buy (71.3%)\n",
      "Example 154 prediction: Buy (70.5%)\n",
      "Example 155 prediction: Buy (70.2%)\n",
      "Example 156 prediction: Buy (73.1%)\n",
      "Example 157 prediction: Buy (69.1%)\n",
      "Example 158 prediction: Buy (73.1%)\n",
      "Example 159 prediction: Not-Buy (55.6%)\n",
      "Example 160 prediction: Buy (71.0%)\n",
      "Example 161 prediction: Not-Buy (59.2%)\n",
      "Example 162 prediction: Not-Buy (73.1%)\n",
      "Example 163 prediction: Not-Buy (71.7%)\n",
      "Example 164 prediction: Buy (70.6%)\n",
      "Example 165 prediction: Not-Buy (62.1%)\n",
      "Example 166 prediction: Not-Buy (62.5%)\n",
      "Example 167 prediction: Not-Buy (59.9%)\n",
      "Example 168 prediction: Buy (71.5%)\n",
      "Example 169 prediction: Buy (71.4%)\n",
      "Example 170 prediction: Buy (73.1%)\n",
      "Example 171 prediction: Not-Buy (73.1%)\n",
      "Example 172 prediction: Not-Buy (63.2%)\n",
      "Example 173 prediction: Buy (69.9%)\n",
      "Example 174 prediction: Not-Buy (63.9%)\n",
      "Example 175 prediction: Not-Buy (67.4%)\n",
      "Example 176 prediction: Not-Buy (60.1%)\n",
      "Example 177 prediction: Buy (70.3%)\n",
      "Example 178 prediction: Not-Buy (72.3%)\n",
      "Example 179 prediction: Buy (70.7%)\n",
      "Example 180 prediction: Not-Buy (73.1%)\n",
      "Example 181 prediction: Not-Buy (54.6%)\n",
      "Example 182 prediction: Buy (70.9%)\n",
      "Example 183 prediction: Buy (72.5%)\n",
      "Example 184 prediction: Buy (71.8%)\n",
      "Example 185 prediction: Not-Buy (73.1%)\n",
      "Example 186 prediction: Buy (69.0%)\n",
      "Example 187 prediction: Buy (73.1%)\n",
      "Example 188 prediction: Not-Buy (67.0%)\n",
      "Example 189 prediction: Buy (72.6%)\n",
      "Example 190 prediction: Not-Buy (72.7%)\n",
      "Example 191 prediction: Not-Buy (63.4%)\n",
      "Example 192 prediction: Buy (70.4%)\n",
      "Example 193 prediction: Buy (73.1%)\n",
      "Example 194 prediction: Not-Buy (73.1%)\n",
      "Example 195 prediction: Not-Buy (73.1%)\n",
      "Example 196 prediction: Not-Buy (73.1%)\n",
      "Example 197 prediction: Buy (65.0%)\n",
      "Example 198 prediction: Buy (73.1%)\n",
      "Example 199 prediction: Not-Buy (73.1%)\n",
      "Example 200 prediction: Not-Buy (73.1%)\n",
      "Example 201 prediction: Not-Buy (73.1%)\n",
      "Example 202 prediction: Not-Buy (68.6%)\n",
      "Example 203 prediction: Buy (72.9%)\n",
      "Example 204 prediction: Buy (73.1%)\n",
      "Example 205 prediction: Buy (73.1%)\n",
      "Example 206 prediction: Not-Buy (73.1%)\n",
      "Example 207 prediction: Not-Buy (66.4%)\n",
      "Example 208 prediction: Not-Buy (55.1%)\n",
      "Example 209 prediction: Buy (73.1%)\n",
      "Example 210 prediction: Not-Buy (71.7%)\n",
      "Example 211 prediction: Buy (71.9%)\n",
      "Example 212 prediction: Buy (56.7%)\n",
      "Example 213 prediction: Not-Buy (58.2%)\n",
      "Example 214 prediction: Buy (68.1%)\n",
      "Example 215 prediction: Not-Buy (61.7%)\n",
      "Example 216 prediction: Not-Buy (67.7%)\n",
      "Example 217 prediction: Not-Buy (72.7%)\n",
      "Example 218 prediction: Buy (63.7%)\n",
      "Example 219 prediction: Buy (70.7%)\n",
      "Example 220 prediction: Buy (61.9%)\n",
      "Example 221 prediction: Not-Buy (65.0%)\n",
      "Example 222 prediction: Buy (67.4%)\n",
      "Example 223 prediction: Not-Buy (65.7%)\n",
      "Example 224 prediction: Not-Buy (69.3%)\n",
      "Example 225 prediction: Buy (73.1%)\n",
      "Example 226 prediction: Buy (64.4%)\n",
      "Example 227 prediction: Not-Buy (56.1%)\n",
      "Example 228 prediction: Buy (69.6%)\n",
      "Example 229 prediction: Buy (66.9%)\n",
      "Example 230 prediction: Not-Buy (66.5%)\n",
      "Example 231 prediction: Not-Buy (60.5%)\n",
      "Example 232 prediction: Buy (52.5%)\n",
      "Example 233 prediction: Buy (70.9%)\n",
      "Example 234 prediction: Buy (73.1%)\n",
      "Example 235 prediction: Not-Buy (68.1%)\n",
      "Example 236 prediction: Buy (70.2%)\n",
      "Example 237 prediction: Buy (62.0%)\n",
      "Example 238 prediction: Not-Buy (59.9%)\n",
      "Example 239 prediction: Buy (52.2%)\n",
      "Example 240 prediction: Not-Buy (53.7%)\n",
      "Example 241 prediction: Not-Buy (63.9%)\n",
      "Example 242 prediction: Not-Buy (73.1%)\n",
      "Example 243 prediction: Not-Buy (72.1%)\n",
      "Example 244 prediction: Not-Buy (59.9%)\n",
      "Example 245 prediction: Not-Buy (60.5%)\n",
      "Example 246 prediction: Buy (63.1%)\n",
      "Example 247 prediction: Buy (73.1%)\n",
      "Example 248 prediction: Buy (69.4%)\n",
      "Example 249 prediction: Not-Buy (63.7%)\n",
      "Example 250 prediction: Not-Buy (67.5%)\n",
      "Example 251 prediction: Not-Buy (61.7%)\n",
      "Example 252 prediction: Buy (71.6%)\n",
      "Example 253 prediction: Not-Buy (73.1%)\n",
      "Example 254 prediction: Buy (65.1%)\n",
      "Example 255 prediction: Not-Buy (73.1%)\n",
      "Example 256 prediction: Buy (69.6%)\n",
      "Example 257 prediction: Buy (71.8%)\n",
      "Example 258 prediction: Buy (72.0%)\n",
      "Example 259 prediction: Not-Buy (60.0%)\n",
      "Example 260 prediction: Not-Buy (73.1%)\n",
      "Example 261 prediction: Not-Buy (73.1%)\n",
      "Example 262 prediction: Buy (72.3%)\n",
      "Example 263 prediction: Not-Buy (73.1%)\n",
      "Example 264 prediction: Not-Buy (67.7%)\n",
      "Example 265 prediction: Not-Buy (66.1%)\n",
      "Example 266 prediction: Not-Buy (53.9%)\n",
      "Example 267 prediction: Buy (68.5%)\n",
      "Example 268 prediction: Not-Buy (73.0%)\n",
      "Example 269 prediction: Not-Buy (69.0%)\n",
      "Example 270 prediction: Buy (64.4%)\n",
      "Example 271 prediction: Not-Buy (71.7%)\n",
      "Example 272 prediction: Buy (58.2%)\n",
      "Example 273 prediction: Not-Buy (67.5%)\n",
      "Example 274 prediction: Buy (73.1%)\n",
      "Example 275 prediction: Not-Buy (58.4%)\n",
      "Example 276 prediction: Buy (62.4%)\n",
      "Example 277 prediction: Buy (71.7%)\n",
      "Example 278 prediction: Buy (69.5%)\n",
      "Example 279 prediction: Buy (72.1%)\n",
      "Example 280 prediction: Buy (70.1%)\n",
      "Example 281 prediction: Not-Buy (73.1%)\n",
      "Example 282 prediction: Not-Buy (73.1%)\n",
      "Example 283 prediction: Not-Buy (71.1%)\n",
      "Example 284 prediction: Not-Buy (73.1%)\n",
      "Example 285 prediction: Not-Buy (72.7%)\n",
      "Example 286 prediction: Not-Buy (73.1%)\n",
      "Example 287 prediction: Buy (71.5%)\n",
      "Example 288 prediction: Buy (73.1%)\n",
      "Example 289 prediction: Not-Buy (66.0%)\n",
      "Example 290 prediction: Buy (57.2%)\n",
      "Example 291 prediction: Not-Buy (61.2%)\n",
      "Example 292 prediction: Buy (70.7%)\n",
      "Example 293 prediction: Not-Buy (73.1%)\n",
      "Example 294 prediction: Not-Buy (73.0%)\n",
      "Example 295 prediction: Not-Buy (64.8%)\n",
      "Example 296 prediction: Buy (73.1%)\n",
      "Example 297 prediction: Buy (66.8%)\n",
      "Example 298 prediction: Buy (73.1%)\n",
      "Example 299 prediction: Not-Buy (58.0%)\n",
      "Example 300 prediction: Not-Buy (72.8%)\n",
      "Example 301 prediction: Buy (73.1%)\n",
      "Example 302 prediction: Buy (73.1%)\n",
      "Example 303 prediction: Buy (73.1%)\n",
      "Example 304 prediction: Buy (65.9%)\n",
      "Example 305 prediction: Not-Buy (64.5%)\n",
      "Example 306 prediction: Not-Buy (58.4%)\n",
      "Example 307 prediction: Buy (73.1%)\n",
      "Example 308 prediction: Not-Buy (64.4%)\n",
      "Example 309 prediction: Buy (70.3%)\n",
      "Example 310 prediction: Not-Buy (66.7%)\n",
      "Example 311 prediction: Not-Buy (63.4%)\n",
      "Example 312 prediction: Buy (69.1%)\n",
      "Example 313 prediction: Buy (73.1%)\n",
      "Example 314 prediction: Buy (68.6%)\n",
      "Example 315 prediction: Not-Buy (73.1%)\n",
      "Example 316 prediction: Buy (73.1%)\n",
      "Example 317 prediction: Buy (55.9%)\n",
      "Example 318 prediction: Not-Buy (73.1%)\n",
      "Example 319 prediction: Buy (54.2%)\n",
      "Example 320 prediction: Not-Buy (68.8%)\n",
      "Example 321 prediction: Buy (68.8%)\n",
      "Example 322 prediction: Not-Buy (66.1%)\n",
      "Example 323 prediction: Not-Buy (62.7%)\n",
      "Example 324 prediction: Not-Buy (61.7%)\n",
      "Example 325 prediction: Not-Buy (73.1%)\n",
      "Example 326 prediction: Buy (73.1%)\n",
      "Example 327 prediction: Not-Buy (62.3%)\n",
      "Example 328 prediction: Buy (73.1%)\n",
      "Example 329 prediction: Buy (73.0%)\n",
      "Example 330 prediction: Buy (72.2%)\n",
      "Example 331 prediction: Not-Buy (54.6%)\n",
      "Example 332 prediction: Buy (70.2%)\n",
      "Example 333 prediction: Buy (72.6%)\n",
      "Example 334 prediction: Buy (73.1%)\n",
      "Example 335 prediction: Not-Buy (68.0%)\n",
      "Example 336 prediction: Buy (70.8%)\n",
      "Example 337 prediction: Buy (73.0%)\n",
      "Example 338 prediction: Buy (51.1%)\n",
      "Example 339 prediction: Buy (73.1%)\n",
      "Example 340 prediction: Not-Buy (60.5%)\n",
      "Example 341 prediction: Not-Buy (66.0%)\n",
      "Example 342 prediction: Not-Buy (62.0%)\n",
      "Example 343 prediction: Not-Buy (73.1%)\n",
      "Example 344 prediction: Buy (72.6%)\n",
      "Example 345 prediction: Buy (71.8%)\n",
      "Example 346 prediction: Not-Buy (73.1%)\n",
      "Example 347 prediction: Not-Buy (54.9%)\n",
      "Example 348 prediction: Buy (70.5%)\n",
      "Example 349 prediction: Buy (70.9%)\n",
      "Example 350 prediction: Buy (70.9%)\n",
      "Example 351 prediction: Buy (73.1%)\n",
      "Example 352 prediction: Not-Buy (73.1%)\n",
      "Example 353 prediction: Buy (55.4%)\n",
      "Example 354 prediction: Not-Buy (73.1%)\n",
      "Example 355 prediction: Not-Buy (73.1%)\n",
      "Example 356 prediction: Buy (66.9%)\n",
      "Example 357 prediction: Buy (73.1%)\n",
      "Example 358 prediction: Not-Buy (63.9%)\n",
      "Example 359 prediction: Not-Buy (73.1%)\n",
      "Example 360 prediction: Buy (70.5%)\n",
      "Example 361 prediction: Buy (70.7%)\n",
      "Example 362 prediction: Buy (73.1%)\n",
      "Example 363 prediction: Not-Buy (59.9%)\n",
      "Example 364 prediction: Buy (62.8%)\n",
      "Example 365 prediction: Not-Buy (65.2%)\n",
      "Example 366 prediction: Not-Buy (56.1%)\n",
      "Example 367 prediction: Buy (72.3%)\n",
      "Example 368 prediction: Not-Buy (73.0%)\n",
      "Example 369 prediction: Buy (72.4%)\n",
      "Example 370 prediction: Not-Buy (51.4%)\n",
      "Example 371 prediction: Buy (73.1%)\n",
      "Example 372 prediction: Buy (71.3%)\n",
      "Example 373 prediction: Not-Buy (73.1%)\n",
      "Example 374 prediction: Buy (73.1%)\n",
      "Example 375 prediction: Buy (73.1%)\n",
      "Example 376 prediction: Buy (67.1%)\n",
      "Example 377 prediction: Buy (70.1%)\n",
      "Example 378 prediction: Not-Buy (66.5%)\n",
      "Example 379 prediction: Buy (70.8%)\n",
      "Example 380 prediction: Not-Buy (64.9%)\n",
      "Example 381 prediction: Buy (73.1%)\n",
      "Example 382 prediction: Not-Buy (68.5%)\n",
      "Example 383 prediction: Not-Buy (68.5%)\n",
      "Example 384 prediction: Not-Buy (66.2%)\n",
      "Example 385 prediction: Not-Buy (60.2%)\n",
      "Example 386 prediction: Not-Buy (72.9%)\n",
      "Example 387 prediction: Not-Buy (66.1%)\n",
      "Example 388 prediction: Buy (68.0%)\n",
      "Example 389 prediction: Buy (73.1%)\n",
      "Example 390 prediction: Buy (70.9%)\n",
      "Example 391 prediction: Buy (69.3%)\n",
      "Example 392 prediction: Buy (70.9%)\n",
      "Example 393 prediction: Not-Buy (73.1%)\n",
      "Example 394 prediction: Buy (69.8%)\n",
      "Example 395 prediction: Not-Buy (73.1%)\n",
      "Example 396 prediction: Not-Buy (67.4%)\n",
      "Example 397 prediction: Not-Buy (68.2%)\n",
      "Example 398 prediction: Buy (70.3%)\n",
      "Example 399 prediction: Not-Buy (54.6%)\n",
      "Example 400 prediction: Buy (70.9%)\n",
      "Example 401 prediction: Not-Buy (58.6%)\n",
      "Example 402 prediction: Not-Buy (68.2%)\n",
      "Example 403 prediction: Not-Buy (66.5%)\n",
      "Example 404 prediction: Buy (71.2%)\n",
      "Example 405 prediction: Buy (51.5%)\n",
      "Example 406 prediction: Buy (70.6%)\n",
      "Example 407 prediction: Not-Buy (73.0%)\n",
      "Example 408 prediction: Buy (67.3%)\n",
      "Example 409 prediction: Not-Buy (62.7%)\n",
      "Example 410 prediction: Not-Buy (73.0%)\n",
      "Example 411 prediction: Buy (70.2%)\n",
      "Example 412 prediction: Not-Buy (73.1%)\n",
      "Example 413 prediction: Buy (72.2%)\n",
      "Example 414 prediction: Buy (71.0%)\n",
      "Example 415 prediction: Not-Buy (73.1%)\n",
      "Example 416 prediction: Not-Buy (73.1%)\n",
      "Example 417 prediction: Not-Buy (73.1%)\n",
      "Example 418 prediction: Buy (70.6%)\n",
      "Example 419 prediction: Buy (69.4%)\n",
      "Example 420 prediction: Not-Buy (64.1%)\n",
      "Example 421 prediction: Not-Buy (56.2%)\n",
      "Example 422 prediction: Not-Buy (63.3%)\n",
      "Example 423 prediction: Not-Buy (73.1%)\n",
      "Example 424 prediction: Buy (73.1%)\n",
      "Example 425 prediction: Not-Buy (59.9%)\n",
      "Example 426 prediction: Buy (73.1%)\n",
      "Example 427 prediction: Not-Buy (59.9%)\n",
      "Example 428 prediction: Not-Buy (53.0%)\n",
      "Example 429 prediction: Not-Buy (73.1%)\n",
      "Example 430 prediction: Not-Buy (72.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 431 prediction: Buy (58.2%)\n",
      "Example 432 prediction: Not-Buy (68.5%)\n",
      "Example 433 prediction: Not-Buy (72.6%)\n",
      "Example 434 prediction: Buy (69.6%)\n",
      "Example 435 prediction: Not-Buy (73.1%)\n",
      "Example 436 prediction: Not-Buy (65.2%)\n",
      "Example 437 prediction: Buy (55.4%)\n",
      "Example 438 prediction: Buy (71.9%)\n",
      "Example 439 prediction: Buy (71.8%)\n",
      "Example 440 prediction: Not-Buy (67.4%)\n",
      "Example 441 prediction: Buy (69.9%)\n",
      "Example 442 prediction: Not-Buy (66.8%)\n",
      "Example 443 prediction: Not-Buy (73.0%)\n",
      "Example 444 prediction: Not-Buy (66.9%)\n",
      "Example 445 prediction: Not-Buy (68.9%)\n",
      "Example 446 prediction: Buy (67.1%)\n",
      "Example 447 prediction: Buy (70.9%)\n"
     ]
    }
   ],
   "source": [
    "predictions = model(test_inputs)\n",
    "class_names = ['Buy', 'Not-Buy']\n",
    "for i, logits in enumerate(predictions):\n",
    "  class_idx = tf.argmax(logits).numpy()\n",
    "  p = tf.nn.softmax(logits)[class_idx]\n",
    "  name = class_names[class_idx]\n",
    "  print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6263, shape=(448, 2), dtype=float32, numpy=\n",
       "array([[9.59809422e-02, 9.04019058e-01],\n",
       "       [9.44087267e-01, 5.59127033e-02],\n",
       "       [8.84664897e-03, 9.91153419e-01],\n",
       "       [3.84557813e-01, 6.15442157e-01],\n",
       "       [9.35128987e-01, 6.48710206e-02],\n",
       "       [1.18563950e-01, 8.81435990e-01],\n",
       "       [6.76299678e-04, 9.99323726e-01],\n",
       "       [1.75945759e-01, 8.24054182e-01],\n",
       "       [3.71449560e-01, 6.28550470e-01],\n",
       "       [2.72902131e-01, 7.27097869e-01],\n",
       "       [1.72046602e-01, 8.27953398e-01],\n",
       "       [9.34883416e-01, 6.51165396e-02],\n",
       "       [1.72966227e-01, 8.27033818e-01],\n",
       "       [7.18894531e-04, 9.99281108e-01],\n",
       "       [9.06849086e-01, 9.31508914e-02],\n",
       "       [1.32682279e-01, 8.67317677e-01],\n",
       "       [1.84791610e-01, 8.15208435e-01],\n",
       "       [9.74225521e-01, 2.57744379e-02],\n",
       "       [9.99478042e-01, 5.22000424e-04],\n",
       "       [9.46068227e-01, 5.39317951e-02],\n",
       "       [9.56177354e-01, 4.38226461e-02],\n",
       "       [2.44730011e-01, 7.55269945e-01],\n",
       "       [4.40501230e-04, 9.99559462e-01],\n",
       "       [1.79945817e-03, 9.98200536e-01],\n",
       "       [8.86456430e-01, 1.13543600e-01],\n",
       "       [9.64142859e-01, 3.58571447e-02],\n",
       "       [2.58128017e-01, 7.41871953e-01],\n",
       "       [9.89057362e-01, 1.09426631e-02],\n",
       "       [9.34801877e-01, 6.51981309e-02],\n",
       "       [6.85629368e-01, 3.14370632e-01],\n",
       "       [3.85242375e-03, 9.96147633e-01],\n",
       "       [9.02025700e-01, 9.79743004e-02],\n",
       "       [9.42294300e-01, 5.77057190e-02],\n",
       "       [1.18073590e-01, 8.81926417e-01],\n",
       "       [9.95244205e-01, 4.75575030e-03],\n",
       "       [9.96363342e-01, 3.63666564e-03],\n",
       "       [8.88264000e-01, 1.11735985e-01],\n",
       "       [3.33621055e-01, 6.66378915e-01],\n",
       "       [9.24043179e-01, 7.59568587e-02],\n",
       "       [9.81729329e-01, 1.82707086e-02],\n",
       "       [9.85159099e-01, 1.48409400e-02],\n",
       "       [9.49253380e-01, 5.07466272e-02],\n",
       "       [9.45018947e-01, 5.49810417e-02],\n",
       "       [1.43592149e-01, 8.56407821e-01],\n",
       "       [8.77458334e-01, 1.22541673e-01],\n",
       "       [1.67038232e-01, 8.32961738e-01],\n",
       "       [1.66170303e-05, 9.99983430e-01],\n",
       "       [8.79403710e-01, 1.20596282e-01],\n",
       "       [9.33898211e-01, 6.61018491e-02],\n",
       "       [2.21107557e-01, 7.78892457e-01],\n",
       "       [4.46301070e-04, 9.99553621e-01],\n",
       "       [8.35357368e-01, 1.64642602e-01],\n",
       "       [3.35203367e-05, 9.99966502e-01],\n",
       "       [9.46403265e-01, 5.35967276e-02],\n",
       "       [7.27868098e-07, 9.99999285e-01],\n",
       "       [3.61525007e-02, 9.63847518e-01],\n",
       "       [6.85686711e-04, 9.99314308e-01],\n",
       "       [9.31946397e-01, 6.80536404e-02],\n",
       "       [9.99965191e-01, 3.47775604e-05],\n",
       "       [1.00000000e+00, 1.47955284e-13],\n",
       "       [9.99999762e-01, 1.94923800e-07],\n",
       "       [9.97854888e-01, 2.14506942e-03],\n",
       "       [9.64173555e-01, 3.58263999e-02],\n",
       "       [1.69615587e-03, 9.98303771e-01],\n",
       "       [9.53523219e-01, 4.64767441e-02],\n",
       "       [1.71426669e-01, 8.28573346e-01],\n",
       "       [9.21708703e-01, 7.82913268e-02],\n",
       "       [1.93616142e-04, 9.99806464e-01],\n",
       "       [1.51646033e-01, 8.48353982e-01],\n",
       "       [9.46623921e-01, 5.33761270e-02],\n",
       "       [4.37023482e-05, 9.99956250e-01],\n",
       "       [1.84741065e-01, 8.15258980e-01],\n",
       "       [1.00000000e+00, 2.38677558e-08],\n",
       "       [9.99998331e-01, 1.69152747e-06],\n",
       "       [4.21154797e-01, 5.78845203e-01],\n",
       "       [9.68012869e-01, 3.19870636e-02],\n",
       "       [5.92326403e-01, 4.07673597e-01],\n",
       "       [1.48844898e-01, 8.51155043e-01],\n",
       "       [9.50654626e-01, 4.93453853e-02],\n",
       "       [9.99971271e-01, 2.86894356e-05],\n",
       "       [7.55391300e-01, 2.44608730e-01],\n",
       "       [8.82492840e-01, 1.17507115e-01],\n",
       "       [9.32936609e-01, 6.70634136e-02],\n",
       "       [1.00000000e+00, 9.65347446e-09],\n",
       "       [9.99986887e-01, 1.31160459e-05],\n",
       "       [3.17939848e-04, 9.99682069e-01],\n",
       "       [4.47972268e-01, 5.52027643e-01],\n",
       "       [1.77826896e-05, 9.99982238e-01],\n",
       "       [4.07833785e-01, 5.92166185e-01],\n",
       "       [9.33532894e-01, 6.64670840e-02],\n",
       "       [4.00703429e-05, 9.99959946e-01],\n",
       "       [9.99999881e-01, 1.68909523e-07],\n",
       "       [9.52765346e-01, 4.72346693e-02],\n",
       "       [1.80714324e-01, 8.19285691e-01],\n",
       "       [6.49520695e-01, 3.50479245e-01],\n",
       "       [8.65895331e-01, 1.34104684e-01],\n",
       "       [9.67562139e-01, 3.24378088e-02],\n",
       "       [9.65343237e-01, 3.46566886e-02],\n",
       "       [1.59907344e-04, 9.99840021e-01],\n",
       "       [1.37594610e-01, 8.62405419e-01],\n",
       "       [8.31145465e-01, 1.68854579e-01],\n",
       "       [1.00000000e+00, 1.69226109e-08],\n",
       "       [9.44580734e-01, 5.54193109e-02],\n",
       "       [1.00000000e+00, 3.17445126e-10],\n",
       "       [9.35992897e-01, 6.40070811e-02],\n",
       "       [2.51042902e-01, 7.48957098e-01],\n",
       "       [9.90251660e-01, 9.74831358e-03],\n",
       "       [9.51518178e-01, 4.84818220e-02],\n",
       "       [2.86845893e-01, 7.13154137e-01],\n",
       "       [1.05624154e-01, 8.94375861e-01],\n",
       "       [1.73697561e-01, 8.26302469e-01],\n",
       "       [6.16056383e-01, 3.83943647e-01],\n",
       "       [9.53523219e-01, 4.64767441e-02],\n",
       "       [1.00000000e+00, 1.78972217e-14],\n",
       "       [3.28887450e-06, 9.99996662e-01],\n",
       "       [4.36837945e-06, 9.99995589e-01],\n",
       "       [9.99692082e-01, 3.07941489e-04],\n",
       "       [9.38309610e-01, 6.16903640e-02],\n",
       "       [6.08598217e-02, 9.39140201e-01],\n",
       "       [9.03594792e-01, 9.64052081e-02],\n",
       "       [8.54847729e-01, 1.45152256e-01],\n",
       "       [2.61514097e-01, 7.38485932e-01],\n",
       "       [1.00708632e-02, 9.89929140e-01],\n",
       "       [2.71607246e-02, 9.72839236e-01],\n",
       "       [9.99966025e-01, 3.39600811e-05],\n",
       "       [9.29057300e-01, 7.09427446e-02],\n",
       "       [1.36935428e-01, 8.63064587e-01],\n",
       "       [9.99408841e-01, 5.91178483e-04],\n",
       "       [1.73842117e-01, 8.26157868e-01],\n",
       "       [8.04676767e-03, 9.91953194e-01],\n",
       "       [7.79066265e-01, 2.20933676e-01],\n",
       "       [9.99999523e-01, 5.24671464e-07],\n",
       "       [9.97620404e-01, 2.37960857e-03],\n",
       "       [9.57737684e-01, 4.22623046e-02],\n",
       "       [4.85903651e-01, 5.14096379e-01],\n",
       "       [2.98433423e-01, 7.01566577e-01],\n",
       "       [6.88885948e-10, 1.00000000e+00],\n",
       "       [9.99998808e-01, 1.16344438e-06],\n",
       "       [9.70876038e-01, 2.91239750e-02],\n",
       "       [1.82158217e-01, 8.17841768e-01],\n",
       "       [8.46051574e-01, 1.53948411e-01],\n",
       "       [8.42527443e-05, 9.99915719e-01],\n",
       "       [9.33587134e-01, 6.64128661e-02],\n",
       "       [1.09852687e-01, 8.90147328e-01],\n",
       "       [2.98433423e-01, 7.01566577e-01],\n",
       "       [1.00000000e+00, 1.50434949e-13],\n",
       "       [8.98049057e-01, 1.01950929e-01],\n",
       "       [1.16780736e-01, 8.83219242e-01],\n",
       "       [1.00000000e+00, 4.06080112e-08],\n",
       "       [1.79151773e-01, 8.20848167e-01],\n",
       "       [1.00000000e+00, 1.02708770e-12],\n",
       "       [1.43009037e-01, 8.56990933e-01],\n",
       "       [2.98433423e-01, 7.01566577e-01],\n",
       "       [9.55371320e-01, 4.46287133e-02],\n",
       "       [9.34857905e-01, 6.51421472e-02],\n",
       "       [9.29570913e-01, 7.04290867e-02],\n",
       "       [9.99955177e-01, 4.48512365e-05],\n",
       "       [9.02660966e-01, 9.73390639e-02],\n",
       "       [1.00000000e+00, 7.10222983e-12],\n",
       "       [3.87058079e-01, 6.12941921e-01],\n",
       "       [9.46890950e-01, 5.31090423e-02],\n",
       "       [3.14046234e-01, 6.85953736e-01],\n",
       "       [4.04274506e-05, 9.99959588e-01],\n",
       "       [3.62241603e-02, 9.63775873e-01],\n",
       "       [9.38740730e-01, 6.12591915e-02],\n",
       "       [2.53832519e-01, 7.46167481e-01],\n",
       "       [2.45016500e-01, 7.54983485e-01],\n",
       "       [2.98433423e-01, 7.01566577e-01],\n",
       "       [9.60547924e-01, 3.94521244e-02],\n",
       "       [9.57602978e-01, 4.23969738e-02],\n",
       "       [9.99999881e-01, 1.62833587e-07],\n",
       "       [4.09283937e-04, 9.99590695e-01],\n",
       "       [2.28606001e-01, 7.71394014e-01],\n",
       "       [9.20726657e-01, 7.92732909e-02],\n",
       "       [2.14491099e-01, 7.85508871e-01],\n",
       "       [1.37517288e-01, 8.62482727e-01],\n",
       "       [2.95119584e-01, 7.04880357e-01],\n",
       "       [9.31101799e-01, 6.88981861e-02],\n",
       "       [1.94045361e-02, 9.80595469e-01],\n",
       "       [9.39519405e-01, 6.04805723e-02],\n",
       "       [4.71881307e-08, 1.00000000e+00],\n",
       "       [4.07833785e-01, 5.92166185e-01],\n",
       "       [9.45488691e-01, 5.45112863e-02],\n",
       "       [9.83915389e-01, 1.60845332e-02],\n",
       "       [9.67085719e-01, 3.29142362e-02],\n",
       "       [4.64557852e-05, 9.99953508e-01],\n",
       "       [8.99023354e-01, 1.00976601e-01],\n",
       "       [1.00000000e+00, 1.38376475e-08],\n",
       "       [1.45868808e-01, 8.54131222e-01],\n",
       "       [9.86624122e-01, 1.33758858e-02],\n",
       "       [1.03564607e-02, 9.89643574e-01],\n",
       "       [2.24835306e-01, 7.75164723e-01],\n",
       "       [9.32507575e-01, 6.74924105e-02],\n",
       "       [9.99998927e-01, 1.12267332e-06],\n",
       "       [5.36062522e-04, 9.99463975e-01],\n",
       "       [3.15067213e-04, 9.99684930e-01],\n",
       "       [1.10009464e-03, 9.98899937e-01],\n",
       "       [8.10191691e-01, 1.89808294e-01],\n",
       "       [1.00000000e+00, 3.03836080e-12],\n",
       "       [5.46219933e-04, 9.99453723e-01],\n",
       "       [1.11452528e-06, 9.99998927e-01],\n",
       "       [1.03266921e-03, 9.98967290e-01],\n",
       "       [1.10345945e-01, 8.89654100e-01],\n",
       "       [9.94334936e-01, 5.66505734e-03],\n",
       "       [9.99994636e-01, 5.39754728e-06],\n",
       "       [9.99961019e-01, 3.89795168e-05],\n",
       "       [5.39353408e-04, 9.99460638e-01],\n",
       "       [1.59376606e-01, 8.40623438e-01],\n",
       "       [3.97739202e-01, 6.02260768e-01],\n",
       "       [1.00000000e+00, 4.20519002e-11],\n",
       "       [3.55765186e-02, 9.64423537e-01],\n",
       "       [9.69890833e-01, 3.01092211e-02],\n",
       "       [6.35660887e-01, 3.64339143e-01],\n",
       "       [3.33621055e-01, 6.66378915e-01],\n",
       "       [8.79582644e-01, 1.20417371e-01],\n",
       "       [2.61514097e-01, 7.38485932e-01],\n",
       "       [1.29860774e-01, 8.70139182e-01],\n",
       "       [1.03284260e-02, 9.89671588e-01],\n",
       "       [7.82160342e-01, 2.17839673e-01],\n",
       "       [9.40325618e-01, 5.96743599e-02],\n",
       "       [7.42978930e-01, 2.57021040e-01],\n",
       "       [1.91517651e-01, 8.08482349e-01],\n",
       "       [8.64125788e-01, 1.35874182e-01],\n",
       "       [1.76070228e-01, 8.23929787e-01],\n",
       "       [9.19312388e-02, 9.08068717e-01],\n",
       "       [1.00000000e+00, 2.60117750e-09],\n",
       "       [7.96750009e-01, 2.03249991e-01],\n",
       "       [3.76769125e-01, 6.23230815e-01],\n",
       "       [9.13554966e-01, 8.64450559e-02],\n",
       "       [8.51277947e-01, 1.48722008e-01],\n",
       "       [1.58132985e-01, 8.41867030e-01],\n",
       "       [2.87790716e-01, 7.12209344e-01],\n",
       "       [5.50128043e-01, 4.49871927e-01],\n",
       "       [9.46403265e-01, 5.35967276e-02],\n",
       "       [9.99983907e-01, 1.60673098e-05],\n",
       "       [1.21767707e-01, 8.78232300e-01],\n",
       "       [9.29570913e-01, 7.04290867e-02],\n",
       "       [7.44154215e-01, 2.55845726e-01],\n",
       "       [2.98433423e-01, 7.01566577e-01],\n",
       "       [5.44027925e-01, 4.55972135e-01],\n",
       "       [4.25432473e-01, 5.74567556e-01],\n",
       "       [2.14320034e-01, 7.85679996e-01],\n",
       "       [7.92626088e-06, 9.99992132e-01],\n",
       "       [2.49827486e-02, 9.75017309e-01],\n",
       "       [2.98433423e-01, 7.01566577e-01],\n",
       "       [2.86845893e-01, 7.13154137e-01],\n",
       "       [7.68716753e-01, 2.31283218e-01],\n",
       "       [9.99999404e-01, 6.24159327e-07],\n",
       "       [9.09837484e-01, 9.01625156e-02],\n",
       "       [2.19258502e-01, 7.80741453e-01],\n",
       "       [1.35418907e-01, 8.64581048e-01],\n",
       "       [2.61514097e-01, 7.38485932e-01],\n",
       "       [9.63170052e-01, 3.68300192e-02],\n",
       "       [8.22800968e-04, 9.99177158e-01],\n",
       "       [8.10805559e-01, 1.89194441e-01],\n",
       "       [7.34181376e-05, 9.99926567e-01],\n",
       "       [9.14916754e-01, 8.50832909e-02],\n",
       "       [9.67562139e-01, 3.24378088e-02],\n",
       "       [9.73113716e-01, 2.68862676e-02],\n",
       "       [2.97087103e-01, 7.02912867e-01],\n",
       "       [1.36844013e-04, 9.99863148e-01],\n",
       "       [8.46988132e-06, 9.99991536e-01],\n",
       "       [9.79115784e-01, 2.08841320e-02],\n",
       "       [1.76634116e-04, 9.99823391e-01],\n",
       "       [1.29965857e-01, 8.70034099e-01],\n",
       "       [1.65047556e-01, 8.34952474e-01],\n",
       "       [4.21154797e-01, 5.78845203e-01],\n",
       "       [8.87379587e-01, 1.12620376e-01],\n",
       "       [2.82786135e-03, 9.97172177e-01],\n",
       "       [9.90190655e-02, 9.00980890e-01],\n",
       "       [7.96422541e-01, 2.03577429e-01],\n",
       "       [3.62197571e-02, 9.63780224e-01],\n",
       "       [6.66236877e-01, 3.33763093e-01],\n",
       "       [1.35075882e-01, 8.64924073e-01],\n",
       "       [9.99995112e-01, 4.86685849e-06],\n",
       "       [3.31365228e-01, 6.68634832e-01],\n",
       "       [7.52970695e-01, 2.47029305e-01],\n",
       "       [9.64085937e-01, 3.59141156e-02],\n",
       "       [9.12541032e-01, 8.74589607e-02],\n",
       "       [9.74426329e-01, 2.55737044e-02],\n",
       "       [9.26196396e-01, 7.38035962e-02],\n",
       "       [5.75683662e-05, 9.99942422e-01],\n",
       "       [2.59181717e-04, 9.99740779e-01],\n",
       "       [4.99852821e-02, 9.50014710e-01],\n",
       "       [2.52858736e-05, 9.99974728e-01],\n",
       "       [1.14632193e-02, 9.88536716e-01],\n",
       "       [8.97441583e-04, 9.99102592e-01],\n",
       "       [9.58706081e-01, 4.12939154e-02],\n",
       "       [9.99734342e-01, 2.65613926e-04],\n",
       "       [1.68439180e-01, 8.31560850e-01],\n",
       "       [6.44937336e-01, 3.55062693e-01],\n",
       "       [2.72166908e-01, 7.27833092e-01],\n",
       "       [9.40179527e-01, 5.98204359e-02],\n",
       "       [1.09673012e-03, 9.98903275e-01],\n",
       "       [2.02076905e-03, 9.97979224e-01],\n",
       "       [1.95932686e-01, 8.04067254e-01],\n",
       "       [9.99971628e-01, 2.83917598e-05],\n",
       "       [8.48598182e-01, 1.51401818e-01],\n",
       "       [9.98991549e-01, 1.00850407e-03],\n",
       "       [3.38512897e-01, 6.61487103e-01],\n",
       "       [8.97525251e-03, 9.91024733e-01],\n",
       "       [9.98848200e-01, 1.15179003e-03],\n",
       "       [1.00000000e+00, 9.57734055e-14],\n",
       "       [9.99999762e-01, 1.85967437e-07],\n",
       "       [8.28781426e-01, 1.71218619e-01],\n",
       "       [2.01656580e-01, 7.98343420e-01],\n",
       "       [3.30714047e-01, 6.69285953e-01],\n",
       "       [1.00000000e+00, 4.99489943e-08],\n",
       "       [2.04364389e-01, 7.95635581e-01],\n",
       "       [9.31587696e-01, 6.84123635e-02],\n",
       "       [1.51704296e-01, 8.48295689e-01],\n",
       "       [2.24965796e-01, 7.75034189e-01],\n",
       "       [9.02379751e-01, 9.76202637e-02],\n",
       "       [1.00000000e+00, 8.98373715e-14],\n",
       "       [8.91446829e-01, 1.08553231e-01],\n",
       "       [1.02251281e-04, 9.99897718e-01],\n",
       "       [1.00000000e+00, 4.01725941e-08],\n",
       "       [6.19537354e-01, 3.80462617e-01],\n",
       "       [1.00056932e-05, 9.99989986e-01],\n",
       "       [5.84666073e-01, 4.15333956e-01],\n",
       "       [1.05731718e-01, 8.94268215e-01],\n",
       "       [8.94968808e-01, 1.05031155e-01],\n",
       "       [1.66530803e-01, 8.33469152e-01],\n",
       "       [2.40956217e-01, 7.59043753e-01],\n",
       "       [2.61650741e-01, 7.38349319e-01],\n",
       "       [3.68326073e-05, 9.99963164e-01],\n",
       "       [9.99964595e-01, 3.53770265e-05],\n",
       "       [2.48238683e-01, 7.51761377e-01],\n",
       "       [1.00000000e+00, 8.75503336e-10],\n",
       "       [9.96719420e-01, 3.28051834e-03],\n",
       "       [9.77954507e-01, 2.20455173e-02],\n",
       "       [4.07833785e-01, 5.92166185e-01],\n",
       "       [9.27226603e-01, 7.27734342e-02],\n",
       "       [9.88280296e-01, 1.17196990e-02],\n",
       "       [1.00000000e+00, 1.90021745e-14],\n",
       "       [1.23157598e-01, 8.76842380e-01],\n",
       "       [9.43237066e-01, 5.67629598e-02],\n",
       "       [9.98073816e-01, 1.92619185e-03],\n",
       "       [5.21644652e-01, 4.78355318e-01],\n",
       "       [9.99996662e-01, 3.32988384e-06],\n",
       "       [2.87790716e-01, 7.12209344e-01],\n",
       "       [1.68559924e-01, 8.31440032e-01],\n",
       "       [2.54719019e-01, 7.45280981e-01],\n",
       "       [1.67207119e-07, 9.99999881e-01],\n",
       "       [9.87453282e-01, 1.25467759e-02],\n",
       "       [9.67562139e-01, 3.24378088e-02],\n",
       "       [4.33542649e-04, 9.99566495e-01],\n",
       "       [4.01398867e-01, 5.98601162e-01],\n",
       "       [9.34482694e-01, 6.55172840e-02],\n",
       "       [9.46165740e-01, 5.38342409e-02],\n",
       "       [9.46403265e-01, 5.35967276e-02],\n",
       "       [1.00000000e+00, 5.62730777e-14],\n",
       "       [1.14721840e-03, 9.98852730e-01],\n",
       "       [6.08823419e-01, 3.91176522e-01],\n",
       "       [1.49804023e-07, 9.99999881e-01],\n",
       "       [3.55838692e-09, 1.00000000e+00],\n",
       "       [8.52482855e-01, 1.47517085e-01],\n",
       "       [9.99975324e-01, 2.46871659e-05],\n",
       "       [2.14699894e-01, 7.85300136e-01],\n",
       "       [1.96111796e-04, 9.99803960e-01],\n",
       "       [9.34801877e-01, 6.51981309e-02],\n",
       "       [9.40179527e-01, 5.98204359e-02],\n",
       "       [9.99999285e-01, 6.60996250e-07],\n",
       "       [2.98433423e-01, 7.01566577e-01],\n",
       "       [7.60899127e-01, 2.39100873e-01],\n",
       "       [1.86027214e-01, 8.13972771e-01],\n",
       "       [3.78039330e-01, 6.21960640e-01],\n",
       "       [9.80337620e-01, 1.96624156e-02],\n",
       "       [2.69503263e-03, 9.97304916e-01],\n",
       "       [9.81144845e-01, 1.88551210e-02],\n",
       "       [4.71280903e-01, 5.28719127e-01],\n",
       "       [9.99999881e-01, 1.20752873e-07],\n",
       "       [9.53859210e-01, 4.61408384e-02],\n",
       "       [5.95604979e-05, 9.99940395e-01],\n",
       "       [1.00000000e+00, 2.32230884e-11],\n",
       "       [9.99997973e-01, 2.04269168e-06],\n",
       "       [8.57465148e-01, 1.42534822e-01],\n",
       "       [9.26943600e-01, 7.30564222e-02],\n",
       "       [1.57232359e-01, 8.42767596e-01],\n",
       "       [9.42396343e-01, 5.76036833e-02],\n",
       "       [1.92345321e-01, 8.07654619e-01],\n",
       "       [1.00000000e+00, 3.94181107e-13],\n",
       "       [1.11336708e-01, 8.88663292e-01],\n",
       "       [1.11145459e-01, 8.88854504e-01],\n",
       "       [1.64677620e-01, 8.35322380e-01],\n",
       "       [2.93479145e-01, 7.06520915e-01],\n",
       "       [4.32661828e-03, 9.95673358e-01],\n",
       "       [1.66385517e-01, 8.33614469e-01],\n",
       "       [8.76807272e-01, 1.23192713e-01],\n",
       "       [1.00000000e+00, 2.13874789e-13],\n",
       "       [9.45432723e-01, 5.45673147e-02],\n",
       "       [9.08195555e-01, 9.18044597e-02],\n",
       "       [9.45929289e-01, 5.40706888e-02],\n",
       "       [3.25594351e-09, 1.00000000e+00],\n",
       "       [9.18720186e-01, 8.12797993e-02],\n",
       "       [5.10118611e-04, 9.99489903e-01],\n",
       "       [1.36049733e-01, 8.63950253e-01],\n",
       "       [1.18858159e-01, 8.81141841e-01],\n",
       "       [9.30813730e-01, 6.91862702e-02],\n",
       "       [4.07833785e-01, 5.92166185e-01],\n",
       "       [9.45563078e-01, 5.44369705e-02],\n",
       "       [3.27169448e-01, 6.72830582e-01],\n",
       "       [1.18075654e-01, 8.81924391e-01],\n",
       "       [1.57938138e-01, 8.42061818e-01],\n",
       "       [9.51880634e-01, 4.81193475e-02],\n",
       "       [5.30603349e-01, 4.69396681e-01],\n",
       "       [9.37742054e-01, 6.22579604e-02],\n",
       "       [3.49675096e-03, 9.96503234e-01],\n",
       "       [8.59873176e-01, 1.40126809e-01],\n",
       "       [2.39955693e-01, 7.60044336e-01],\n",
       "       [1.64481916e-03, 9.98355210e-01],\n",
       "       [9.27542984e-01, 7.24570379e-02],\n",
       "       [2.77727348e-04, 9.99722302e-01],\n",
       "       [9.76655126e-01, 2.33448260e-02],\n",
       "       [9.46890950e-01, 5.31090423e-02],\n",
       "       [4.64176822e-11, 1.00000000e+00],\n",
       "       [3.01567692e-04, 9.99698520e-01],\n",
       "       [5.02235016e-05, 9.99949813e-01],\n",
       "       [9.37708378e-01, 6.22915663e-02],\n",
       "       [9.09349382e-01, 9.06505883e-02],\n",
       "       [2.10702851e-01, 7.89297104e-01],\n",
       "       [3.76152813e-01, 6.23847127e-01],\n",
       "       [2.27284044e-01, 7.72715986e-01],\n",
       "       [5.24691018e-07, 9.99999523e-01],\n",
       "       [1.00000000e+00, 1.02084573e-12],\n",
       "       [2.98433423e-01, 7.01566577e-01],\n",
       "       [1.00000000e+00, 4.78345526e-14],\n",
       "       [2.98433423e-01, 7.01566577e-01],\n",
       "       [4.39802855e-01, 5.60197175e-01],\n",
       "       [8.76682898e-05, 9.99912381e-01],\n",
       "       [1.29352827e-02, 9.87064719e-01],\n",
       "       [6.65974796e-01, 3.34025174e-01],\n",
       "       [1.11548595e-01, 8.88451397e-01],\n",
       "       [1.24340160e-02, 9.87565994e-01],\n",
       "       [9.13028657e-01, 8.69712755e-02],\n",
       "       [1.02995386e-06, 9.99998927e-01],\n",
       "       [1.87037900e-01, 8.12962115e-01],\n",
       "       [6.09243155e-01, 3.90756816e-01],\n",
       "       [9.70858097e-01, 2.91419122e-02],\n",
       "       [9.67562139e-01, 3.24378088e-02],\n",
       "       [1.36023015e-01, 8.63976955e-01],\n",
       "       [9.21485245e-01, 7.85147846e-02],\n",
       "       [1.49769068e-01, 8.50230932e-01],\n",
       "       [3.83797637e-03, 9.96162057e-01],\n",
       "       [1.48132935e-01, 8.51867080e-01],\n",
       "       [1.02741100e-01, 8.97258878e-01],\n",
       "       [8.57106566e-01, 1.42893493e-01],\n",
       "       [9.44965363e-01, 5.50345629e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(test_inputs)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0] *",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
